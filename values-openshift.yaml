# Unified NeuralTrust Platform Values (Optimized)
# This file contains all configuration for deploying NeuralTrust platform components
# including infrastructure (ClickHouse, Kafka, PostgreSQL), NeuralTrust services,
# and TrustGate components.

# Global settings
global:
  openshift: true # set to true if you are using openshift
  openshiftDomain: "YOUR_DOMAIN" # OpenShift wildcard DNS domain (e.g., *.apps.neuraltrust-dev.c4u5.p2.openshiftapps.com)
  imageRegistry: "" # Global image registry prefix (e.g., "europe-west1-docker.pkg.dev/project/repo"). If set, will be prepended to image repositories.
  preserveExistingSecrets: false  # Set to true to prevent Helm from creating/updating secrets (secrets are pre-generated). When true, secret templates are NOT rendered.
  security:
    allowInsecureImages: true # Allow Bitnami charts to use their container images
  storageClass: "" # Global storage class for persistent volumes

# ClickHouse subchart values (passed directly to clickhouse subchart)
# These values are used when infrastructure.clickhouse.deploy=true
clickhouse:
  fullnameOverride: "clickhouse"
  shards: 1
  replicaCount: 1
  zookeeper:
    enabled: false
  image:
    registry: docker.io
    repository: bitnamilegacy/clickhouse  # Set via --set clickhouse.image.repository="your-repo/clickhouse"
    tag: 25.3.2-debian-12-r3
    pullPolicy: Always
  global:
    imagePullSecrets: []  # Empty for public Docker Hub images, or ["user-registry"] for private images
  auth:
    username: "neuraltrust"
    password: "" # Define this value
    # Use existing secret if it already exists (prevents Helm from trying to manage it)
    # Set to "clickhouse" to use the pre-existing secret named "clickhouse"
    existingSecret: ""  # Set to "" if you want Helm to create/manage the secret
    existingSecretKey: "admin-password"  # Key name in the existing secret
  persistence:
    enabled: true
    size: 50Gi
    storageClass: ""
  resources:
    requests:
      memory: 1Gi
      cpu: 1
    limits:
      memory: 2Gi
      cpu: 2
  logLevel: "fatal"

# Kafka subchart values (passed directly to kafka subchart)
# These values are used when infrastructure.kafka.deploy=true
kafka:
  # Small deployment configuration (1 broker, 1 zookeeper)
  fullnameOverride: "kafka"
  kraft:
    enabled: false
  extraConfigYaml:
    default.replication.factor: 1
    offsets.topic.replication.factor: 1
    transaction.state.log.replication.factor: 1
    transaction.state.log.min.isr: 1
    min.insync.replicas: 1
  extraEnvVars:
    - name: KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR
      value: "1"
    - name: KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
      value: "1"
    - name: KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR
      value: "1"
    - name: KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
      value: "1"
    - name: KAFKA_CFG_MIN_INSYNC_REPLICAS
      value: "1"
  auth:
    interBrokerProtocol: PLAINTEXT
    clientProtocol: PLAINTEXT
  listeners:
    client:
      containerPort: 9092
      protocol: PLAINTEXT
      name: CLIENT
      sslClientAuth: ""
    interbroker:
      containerPort: 9094
      protocol: PLAINTEXT
      name: INTERNAL
      sslClientAuth: ""
    controller:
      name: CONTROLLER
      containerPort: 9093
      protocol: PLAINTEXT
      sslClientAuth: ""
  broker:
    replicaCount: 1
    podAntiAffinityPreset: hard
    resources:
      requests:
        memory: 1Gi
        cpu: 500m
      limits:
        memory: 2Gi
        cpu: 1
  zookeeper:
    enabled: true
    fullnameOverride: "zookeeper"
    replicaCount: 1
    podAntiAffinityPreset: hard
    auth:
      client:
        enabled: false
    image:
      registry: docker.io
      repository: bitnamilegacy/zookeeper
      tag: 3.9.3-debian-12-r0
    resources:
      requests:
        cpu: 500m
        memory: 512Mi
      limits:
        cpu: 1000m
        memory: 1Gi
  controller:
    replicaCount: 0
  image:
    registry: docker.io
    repository: bitnamilegacy/kafka
    tag: 3.9.0-debian-12-r1
    pullPolicy: Always
  global:
    imagePullSecrets: []  # Empty for public Docker Hub images, or ["user-registry"] for private images
  persistence:
    enabled: true
    size: 10Gi
    storageClass: ""

# Infrastructure Components
# These can be deployed or configured to use pre-installed instances
infrastructure:
  # ClickHouse Configuration
  clickhouse:
    # Set to true to deploy ClickHouse, false to use pre-installed instance
    # Default: true (deploy)
    deploy: true
    # External ClickHouse configuration (used when deploy: false)
    external:
      host: "clickhouse.clickhouse.svc.cluster.local" # e.g., "clickhouse.clickhouse.svc.cluster.local"
      port: "8123"
      user: "neuraltrust"
      password: "" # Define this value
      database: "neuraltrust"
      # Secret reference for external ClickHouse credentials
      secretName: "clickhouse" # Optional: secret containing CLICKHOUSE_PASSWORD
      secretKey: "admin-password" # Key in secret for password
    # ClickHouse chart values (used when deploy: true)
    # Values are passed via root-level 'clickhouse:' section above

  # Kafka Configuration
  kafka:
    # Set to true to deploy Kafka, false to use pre-installed instance
    # Default: true (deploy)
    deploy: true
    # External Kafka configuration (used when deploy: false)
    external:
      bootstrapServers: "" # e.g., "kafka-kafka-bootstrap.kafka.svc.cluster.local:9092"
      # Or individual brokers:
      brokers: [] # e.g., ["kafka-0.kafka-headless:9092", "kafka-1.kafka-headless:9092"]
      # Secret reference for external Kafka credentials (if using SASL)
      secretName: "" # Optional
      secretKey: "" # Optional
    # Kafka chart values (used when deploy: true)
    # Values are passed via root-level 'kafka:' section above

  # PostgreSQL Configuration
  postgresql:
    # Note: PostgreSQL deployment is controlled by neuraltrust-control-plane.infrastructure.postgresql.deploy below
    # Set deploy: true/false in that section to enable/disable in-cluster PostgreSQL deployment
    # External PostgreSQL configuration (used when neuraltrust-control-plane.infrastructure.postgresql.deploy=false)
    external:
      host: "postgresql.postgresql.svc.cluster.local" # e.g., "postgresql.postgresql.svc.cluster.local"
      port: "5432"
      user: "postgres" # Default: "postgres" for external, "neuraltrust" for in-cluster
      password: "" # Define this value
      database: "neuraltrust"
      # Secret reference for external PostgreSQL credentials
      secretName: "" # Optional: secret containing POSTGRES_PASSWORD
      secretKey: "" # Optional: key in secret for password
    # PostgreSQL chart values (used when deploy: true)
    # Values are passed via 'neuraltrust-control-plane.controlPlane.components.postgresql:' section below

  # Redis Configuration
  # Note: Redis is deployed as part of TrustGate, not as a separate subchart
  # Control Redis deployment via 'trustgate.redis.enabled' (see trustgate.redis section below)
  # External Redis configuration is available in 'trustgate.redis.external' section below

# TrustGate Configuration
trustgate:
  enabled: true
  global:
    version: "ee"  # can be "ce" or "ee"
    imageRegistry: "europe-west1-docker.pkg.dev/neuraltrust-app-prod/nt-docker"
    storageClass: ""
    deploymentType: shared  # shared or dedicated
    huggingface:
      apiKeySecret: "hf-api-key"
    image:
      pullPolicy: Always
      image: "europe-west1-docker.pkg.dev/neuraltrust-app-prod/nt-docker/trustgate-ee"
      tag: "v1.9.50"
      # imagePullSecrets: if not set, will fall back to parent chart's global.imagePullSecrets
      imagePullSecrets: ["user-registry"]  # Set to array of secret names, e.g., ["secret-name"] or leave empty to use parent global.imagePullSecrets
    env:
      SERVER_SECRET_KEY: ""  # Define this value
      SERVER_BASE_DOMAIN: "yourdomain.com"  # Set to your domain
      SERVER_ADMIN_PORT: "8080"
      SERVER_METRICS_PORT: "9090"
      SERVER_PROXY_PORT: "8081"
      SERVER_ACTIONS_PORT: "8084"
      # Database connection (uses infrastructure.postgresql config)
      # When control-plane PostgreSQL is installed in-cluster (infrastructure.postgresql.deploy=true), use:
      # - DATABASE_HOST: "control-plane-postgresql" (service name)
      # - DATABASE_USER: "neuraltrust" (matches control-plane PostgreSQL user)
      # - DATABASE_PASSWORD: same as control-plane PostgreSQL password
      DATABASE_HOST: "control-plane-postgresql"  # Use control-plane PostgreSQL service name when infrastructure.postgresql.deploy=true
      DATABASE_PORT: "5432"
      DATABASE_USER: "trustgate"
      DATABASE_PASSWORD: "" #define this value
      DATABASE_NAME: "trustgate"
      # PostgreSQL SSL mode (disable, require, verify-ca, verify-full)
      # Use "disable" when infrastructure.postgresql.deploy=true, "require" for external PostgreSQL
      DATABASE_SSL_MODE: "disable"  # Use "disable" for in-cluster PostgreSQL, "require" for external
      # Redis connection
      REDIS_HOST: ""  # Will be auto-configured if redis.enabled
      REDIS_PORT: "6379"
      REDIS_DB: "0"

  # Service Account configuration
  serviceAccount:
    create: true
    name: ""
    annotations: {}

  # Common configurations
  config:
    logLevel: "info"
    baseDomain: "yourdomain.com"  # Set to your domain
    providers: {}

  # Control Plane settings
  controlPlane:
    name: trustgate-control-plane
    replicas: 1
    ports:
      http: 8080
    podSecurityContext:
      fsGroup: 1001
    resources:
      requests:
        cpu: 100m
        memory: 1Gi
      limits:
        cpu: 200m
        memory: 2Gi
    podDisruptionBudget:
      enabled: true
      minAvailable: 1
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 10
      targetCPUUtilizationPercentage: 80
      targetMemoryUtilizationPercentage: 80
    nodeSelector: {}
    tolerations: []
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - trustgate-control-plane
              topologyKey: kubernetes.io/hostname
    service:
      type: ClusterIP
      port: 8080

  # Data Plane settings
  dataPlane:
    name: trustgate-data-plane
    replicas: 1
    resources:
      requests:
        cpu: 1000m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 4Gi
    ports:
      http: 8081
    podDisruptionBudget:
      enabled: true
      minAvailable: 2
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 20
      targetCPUUtilizationPercentage: 75
      targetMemoryUtilizationPercentage: 75
    nodeSelector: {}
    tolerations: []
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: app
                  operator: In
                  values:
                    - trustgate-data-plane
            topologyKey: kubernetes.io/hostname
    service:
      type: ClusterIP
      port: 8081

  # Actions settings
  actions:
    name: trustgate-actions
    replicas: 1
    ports:
      http: 8084
    podSecurityContext:
      fsGroup: 1001
    resources:
      requests:
        cpu: 100m
        memory: 1Gi
      limits:
        cpu: 200m
        memory: 2Gi
    podDisruptionBudget:
      enabled: true
      minAvailable: 1
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 5
      targetCPUUtilizationPercentage: 80
      targetMemoryUtilizationPercentage: 80
    nodeSelector: {}
    tolerations: []
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - trustgate-actions
              topologyKey: kubernetes.io/hostname
    service:
      type: ClusterIP
      port: 8084

  # Redis configuration
  redis:
    enabled: true
    image:
      repository: redislabs/redisearch
      tag: 2.6.9
      pullPolicy: Always
      imagePullSecrets: []  # Empty for public Docker Hub images, or ["user-registry"] for private images
    # External Redis configuration if redis.enabled is false
    external:
      host: ""
      port: 6379
      password: ""  # Optional - recommended when using external Redis (redis.enabled: false)
    master:
      service:
        port: 6379
      persistence:
        enabled: true
        size: 10Gi
      resources:
        requests:
          cpu: 500m
          memory: 1Gi
        limits:
          cpu: 1000m
          memory: 2Gi
    replica:
      replicaCount: 1
      service:
        port: 6379

  # Monitoring settings
  monitoring:
    serviceMonitor:
      enabled: false
      interval: 30s
      labels: {}
    external:
      enabled: false
      endpoint: ""
      scrapeInterval: 30s
    grafanaDashboards:
      enabled: true
    prometheusRules:
      enabled: true
      rules:
        - alert: HighErrorRate
          expr: rate(http_requests_total{status=~"5.."}[5m]) > 1
          for: 5m
          labels:
            severity: critical
          annotations:
            description: High error rate detected
    logging:
      enabled: true
      elasticsearch:
        enabled: true
        replicas: 3

  ingress:
    enabled: false  # Set to true to use Ingress instead of Routes in OpenShift
    className: "openshift-default"  # Ingress class name (e.g., "nginx", "traefik", "openshift-default")
    annotations:
      route.openshift.io/termination: "edge"
      route.openshift.io/insecure-edge-termination-policy: "Redirect"
    controlPlane:
      host: "admin.yourdomain.com"  # Set to your domain
    dataPlane:
      host: "gateway.yourdomain.com"  # Set to your domain
    actions:
      host: "actions.yourdomain.com"  # Set to your domain
    # TLS configuration for Ingress (when ingress.enabled: true)
    # When using an existing wildcard TLS secret (type: kubernetes.io/tls) in the namespace,
    # set tls.enabled: true and tls.secretName to the name of that secret
    # The secret should contain tls.crt and tls.key keys
    tls:
      enabled: false
      secretName: ""  # Name of existing kubernetes.io/tls secret in namespace


# NeuralTrust Control Plane subchart values
# Helm requires values to be passed to subcharts using the subchart name as a prefix
neuraltrust-control-plane:
  infrastructure:
    postgresql:
      deploy: true  # Deploy PostgreSQL in-cluster (set to false to use external PostgreSQL)
  controlPlane:
    enabled: true
    imagePullSecrets: "user-registry"  # Set imagePullSecrets for all control-plane components (scheduler, api, app, postgresql)
    secrets:
      controlPlaneJWTSecret: "" #define this value
      openaiApiKey: ""
      resendApiKey: ""
      resendAlertSender: ""
      resendInviteSender: ""
      trustgateJwtSecret: "" #define this value
      firewallJwtSecret: ""
      modelScannerSecret: ""
    components:
      scheduler:
        enabled: true
        host: "control-plane-scheduler.yourdomain.com"  # Set to your domain
        service:
          type: ClusterIP  # Use ClusterIP for OpenShift (Routes handle external access)
        ingress:
          enabled: false  # Set to true to use Ingress instead of Routes in OpenShift
          className: "openshift-default"  # Ingress class name (e.g., "nginx", "traefik", "openshift-default")
          annotations:
            route.openshift.io/termination: "edge"
            route.openshift.io/insecure-edge-termination-policy: "Redirect"
          # TLS configuration for Ingress (when ingress.enabled: true)
          # When using an existing wildcard TLS secret (type: kubernetes.io/tls) in the namespace,
          # set tls.secretName to the name of that secret
          # The secret should contain tls.crt and tls.key keys
          tls:
            enabled: false
            secretName: ""  # Name of existing kubernetes.io/tls secret in namespace
        replicaCount: 1
        image:
          repository: "europe-west1-docker.pkg.dev/neuraltrust-app-prod/nt-docker/scheduler"
          tag: "v1.8.0"
          pullPolicy: "Always"
        config:
          # URLs will be auto-generated from OpenShift Routes if global.openshift=true and global.openshiftDomain is set
          # Otherwise, set these manually or they will default to internal service URLs
          controlPlaneApiUrl: ""  # Auto: https://control-plane-api.{global.openshiftDomain} or http://control-plane-api-service.{namespace}.svc.cluster.local
          dataPlaneApiUrl: ""  # Auto: https://data-plane-api.{global.openshiftDomain} or http://data-plane-api-service.{namespace}.svc.cluster.local
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 200m
      api:
        enabled: true
        host: "control-plane-api.yourdomain.com"  # Set to your domain
        service:
          type: ClusterIP  # Use ClusterIP for OpenShift (Routes handle external access)
        ingress:
          enabled: false  # Set to true to use Ingress instead of Routes in OpenShift
          className: "openshift-default"  # Ingress class name (e.g., "nginx", "traefik", "openshift-default")
          annotations:
            route.openshift.io/termination: "edge"
            route.openshift.io/insecure-edge-termination-policy: "Redirect"
          # TLS configuration for Ingress (when ingress.enabled: true)
          # When using an existing wildcard TLS secret (type: kubernetes.io/tls) in the namespace,
          # set tls.secretName to the name of that secret
          # The secret should contain tls.crt and tls.key keys
          tls:
            enabled: false
            secretName: ""  # Name of existing kubernetes.io/tls secret in namespace
        replicaCount: 2
        image:
          repository: "europe-west1-docker.pkg.dev/neuraltrust-app-prod/nt-docker/control-plane-api"
          tag: "v1.8.2"
          pullPolicy: "Always"
        secrets:
          controlPlaneJWTSecret: "" #define this value
        config:
          # URLs will be auto-generated from OpenShift Routes if global.openshift=true and global.openshiftDomain is set
          # Otherwise, set these manually or they will default to internal service URLs
          controlPlaneApiUrl: ""  # Auto: https://control-plane-api.{global.openshiftDomain} or http://control-plane-api-service.{namespace}.svc.cluster.local
          dataPlaneApiUrl: ""  # Auto: https://data-plane-api.{global.openshiftDomain} or http://data-plane-api-service.{namespace}.svc.cluster.local
        resources:
          requests:
            memory: 512Mi
            cpu: 250m
          limits:
            memory: 1Gi
            cpu: 500m
      app:
        enabled: true
        host: "control-plane-app.yourdomain.com"  # Set to your domain
        secondaryHost: ""
        service:
          type: ClusterIP  # Use ClusterIP for OpenShift (Routes handle external access)
        ingress:
          enabled: false  # Set to true to use Ingress instead of Routes in OpenShift
          className: "openshift-default"  # Ingress class name (e.g., "nginx", "traefik", "openshift-default")
          annotations:
            route.openshift.io/termination: "edge"
            route.openshift.io/insecure-edge-termination-policy: "Redirect"
          # TLS configuration for Ingress (when ingress.enabled: true)
          # When using an existing wildcard TLS secret (type: kubernetes.io/tls) in the namespace,
          # set tls.secretName to the name of that secret
          # The secret should contain tls.crt and tls.key keys
          tls:
            enabled: false
            secretName: ""  # Name of existing kubernetes.io/tls secret in namespace
        replicaCount: 1
        image:
          repository: "europe-west1-docker.pkg.dev/neuraltrust-app-prod/nt-docker/app"
          tag: "v1.8.0"
          pullPolicy: "Always"
        config:
          nodeEnv: production
          port: 3000
          # URLs will be auto-generated from OpenShift Routes if global.openshift=true and global.openshiftDomain is set
          # Otherwise, set these manually or they will default to internal service URLs
          controlPlaneApiUrl: ""  # Auto: https://control-plane-api.{global.openshiftDomain} or http://control-plane-api-service:80 (same namespace)
          dataPlaneApiUrl: ""  # Auto: https://data-plane-api.{global.openshiftDomain} or http://data-plane-api-service:80 (same namespace)
          schedulerUrl: ""  # Auto: https://control-plane-scheduler.{global.openshiftDomain} or http://control-plane-scheduler-service:80 (same namespace)
          trustgateControlPlaneUrl: ""  # Auto: https://trustgate-admin.{global.openshiftDomain} or http://trustgate-control-plane:80 (same namespace)
          trustgateDataPlaneUrl: ""  # Auto: https://trustgate-gateway.{global.openshiftDomain} or http://trustgate-data-plane:80 (same namespace)
          trustgateActionsUrl: ""  # Auto: https://trustgate-actions.{global.openshiftDomain} or http://trustgate-actions:80 (same namespace)
          nextAuthUrl: ""  # Auto: https://{app.host} or https://control-plane-app.yourdomain.com
          firewallApiUrl: ""
          modelScannerApiUrl: ""
          openaiModel: "gpt-4o-mini"
          kafkaHost: "kafka"
          kafkaPort: "9092"
        resources:
          requests:
            memory: 512Mi
            cpu: 250m
          limits:
            memory: 1Gi
            cpu: 500m
        initContainer:
          resources:
            requests:
              memory: 512Mi
              cpu: 250m
            limits:
              memory: 1Gi
              cpu: 500m
      postgresql:
        secrets:
          name: "postgresql-secrets"
          user: "neuraltrust"  # PostgreSQL user (default: "neuraltrust" for in-cluster, "postgres" for external)
          password: ""  # PostgreSQL password (required when infrastructure.postgresql.deploy=true or using external PostgreSQL)
          database: "neuraltrust"  # PostgreSQL database name
          host: "control-plane-postgresql"  # PostgreSQL host (set to "control-plane-postgresql" when infrastructure.postgresql.deploy=true, or external host when using external PostgreSQL)
          port: "5432"  # PostgreSQL port
        image:
          repository: "postgres"
          tag: "17.2-alpine"
          pullPolicy: "Always"
          imagePullSecrets:
            - name: "user-registry"
        persistence:
          enabled: true
          size: 10Gi
          storageClass: ""
          preserveOnDelete: true
        resources:
          requests:
            memory: 512Mi
            cpu: 250m
          limits:
            memory: 1Gi
            cpu: 500m
        service:
          type: ClusterIP
          port: 5432

# NeuralTrust Data Plane subchart values
# Helm requires values to be passed to subcharts using the subchart name as a prefix
neuraltrust-data-plane:
  dataPlane:
    enabled: true
    imagePullSecrets: "user-registry"  # Set imagePullSecrets for all data-plane components (api, worker, kafka-connect)
    secrets:
      openaiApiKeySecretName: "openai-secrets"
      openaiApiKey: ""
      googleApiKeySecretName: "google-secrets"
      googleApiKey: ""
      resendApiKeySecretName: "resend-secrets"
      resendApiKey: ""
      dataPlaneJWTSecretName: "data-plane-jwt-secret"
      dataPlaneJWTSecret: "" #define this value
      huggingFaceTokenSecretName: "huggingface-secrets"
      huggingFaceToken: ""
    components:
      clickhouse:
        enabled: true
        host: "clickhouse"
        port: "8123"
        user: "neuraltrust"
        database: "neuraltrust"
        image:
          repository: "clickhouse/clickhouse-server"
          tag: "25.3.2"
          pullPolicy: "Always"
        auth:
          username: "neuraltrust"
        secrets:
          name: "clickhouse-secrets"
        configmap:
          name: "clickhouse-init-job"
        resources:
          requests:
            memory: 512Mi
            cpu: 250m
          limits:
            memory: 1Gi
            cpu: 500m
      kafka:
        enabled: true
        connect:
          replicas: 1
          image:
            repository: europe-west1-docker.pkg.dev/neuraltrust-app-prod/nt-docker/kafka-connect
            tag: v0.0.1
            pullPolicy: Always
          resources:
            limits:
              cpu: "1"
              memory: 4Gi
            requests:
              cpu: 500m
              memory: 2Gi
      api:
        enabled: true
        host: "data-plane-api.yourdomain.com"  # Set to your domain
        service:
          type: ClusterIP  # Use ClusterIP for OpenShift (Routes handle external access)
        ingress:
          enabled: false  # Set to true to use Ingress instead of Routes in OpenShift
          className: "openshift-default"  # Ingress class name (e.g., "nginx", "traefik", "openshift-default")
          annotations:
            route.openshift.io/termination: "edge"
            route.openshift.io/insecure-edge-termination-policy: "Redirect"
          # TLS configuration for Ingress (when ingress.enabled: true)
          # When using an existing wildcard TLS secret (type: kubernetes.io/tls) in the namespace,
          # set tls.secretName to the name of that secret
          # The secret should contain tls.crt and tls.key keys
          tls:
            enabled: false
            secretName: ""  # Name of existing kubernetes.io/tls secret in namespace
        classifierModel: "gpt"
        image:
          repository: europe-west1-docker.pkg.dev/neuraltrust-app-prod/nt-docker/data-plane-api
          tag: v1.8.3
          pullPolicy: Always
        accessMode: ReadWriteOnce
        huggingfaceToken: ""
        storage: 10Gi
        # TrustTest configuration: Set to {} to enable volume mounting of trusttest config
        # The ConfigMap content is generated from charts/neuraltrust-data-plane/files/.trusttest_config.json
        trustTestConfig: {}
        replicas: 3
        resources:
          requests:
            cpu: 1
            memory: 2Gi
          limits:
            cpu: 2
            memory: 3Gi
      worker:
        enabled: true
        replicas: 1
        image:
          repository: europe-west1-docker.pkg.dev/neuraltrust-app-prod/nt-docker/workers
          tag: v1.4.0-with-models
          pullPolicy: Always
        resources:
          requests:
            memory: 4Gi
            cpu: 1000m
          limits:
            memory: 8Gi
            cpu: 2000m
      connectorsJob:
        image: curlimages/curl:8.13.0
